{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c3b018f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "243e4cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pypdf -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01d5aa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install docx2txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d240c21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wikipedia -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e85dd940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_document(file):\n",
    "    import os\n",
    "    name, extension = os.path.splitext(file)\n",
    "    \n",
    "    if extension == \".pdf\":\n",
    "        from langchain.document_loaders import PyPDFLoader\n",
    "        print(f\"Loading {file}\")\n",
    "        loader = PyPDFLoader(file)\n",
    "    elif extension == \".docx\":\n",
    "        from langchain.document_loaders import Docx2txtLoader\n",
    "        print(f\"Loading {file}\")\n",
    "        loader = Docx2txtLoader(file)\n",
    "    else:\n",
    "        print(\"Document format is not supported!\")\n",
    "        return None\n",
    "    \n",
    "    data = loader.load()\n",
    "    return data\n",
    "\n",
    "# Wikipedia\n",
    "def load_from_wikipedia(query, lang=\"en\", load_max_docs=2):\n",
    "    from langchain.document_loaders import WikipediaLoader\n",
    "    loader = WikipediaLoader(query=query, lang=lang, load_max_docs=load_max_docs)\n",
    "    data = loader.load()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b41b389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_data(data, chunk_size=256):\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=0)\n",
    "    chunks = text_splitter.split_documents(data)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d07befd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_embedding_cost(texts):\n",
    "    import tiktoken\n",
    "    enc = tiktoken.encoding_for_model(\"text-embedding-ada-002\")\n",
    "    total_tokens = sum([len(enc.encode(page.page_content)) for page in texts])\n",
    "    print(f\"Total tokens: {total_tokens}\")\n",
    "    print(f\"Embedding Cost in USD: {total_tokens / 1000 * 0.0004:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a505ceff",
   "metadata": {},
   "source": [
    "### Embedding and Uploading to a Vector Database (Pinecone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5bb810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_or_fetch_embeddings(index_name):\n",
    "    import pinecone\n",
    "    from langchain.vectorstores import Pinecone\n",
    "    from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "    \n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    \n",
    "    pinecone.init(api_key=os.environ.get(\"PINECONE_API_KEY\"), environment=os.environ.get(\"PINECONE_ENV\"))\n",
    "    \n",
    "    if index_name in pinecone.list_indexes():\n",
    "        print(f\"Index {index_name} already exists. Loading embeddings ...\", end=\"\")\n",
    "        vector_store = Pinecone.from_existing_index(index_name, embeddings)\n",
    "    else:\n",
    "        print(f\"Creating index {index_name} and embeddings ...\", end=\"\")\n",
    "        pinecone.create_index(index_name, dimension=1536, metric=\"cosine\")\n",
    "        vector_store = Pinecone.from_documents(chunks, embeddings, index_name=index_name)\n",
    "        print(\"Ok\")\n",
    "    \n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19aaccd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_pinecone_index(index_name=\"all\"):\n",
    "    import pinecone\n",
    "    pinecone.init(api_key=os.environ.get(\"PINECONE_API_KEY\"), environment=os.environ.get(\"PINECONE_ENV\"))\n",
    "    \n",
    "    if index_name == \"all\":\n",
    "        indexes = pinecone.list_indexes()\n",
    "        print(\"Deleting all indexes ...\")\n",
    "        for index in indexes:\n",
    "            pinecone.delete_index(index)\n",
    "        print(\"Ok\")\n",
    "    else:\n",
    "        print(f\"Deleting index {index_name} ...\", end=\"\")\n",
    "        pinecone.delete_index(index_name)\n",
    "        print(\"Ok\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e113cb3",
   "metadata": {},
   "source": [
    "### Asking and Getting Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e625ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_and_get_answer(vector_store, q):\n",
    "    from langchain.chains import RetrievalQA\n",
    "    from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=1)\n",
    "\n",
    "    retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\" : 3})\n",
    "\n",
    "    chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
    "    \n",
    "    answer = chain.run(q)\n",
    "    \n",
    "    return answer\n",
    "\n",
    "def ask_with_memory(vector_store, question, chat_history=[]):\n",
    "    from langchain.chains import ConversationalRetrievalChain\n",
    "    from langchain.chat_models import ChatOpenAI\n",
    "    \n",
    "    llm = ChatOpenAI(temperature=1)\n",
    "    retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k' : 3})\n",
    "    \n",
    "    crc = ConversationalRetrievalChain.from_llm(llm, retriever)\n",
    "    result = crc({'question' : question, 'chat_history' : chat_history})\n",
    "    chat_history.append((question, result['answer']))\n",
    "    \n",
    "    return result, chat_history  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e987f35",
   "metadata": {},
   "source": [
    "### Running Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5ed6911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files/us_constitution.pdf\n",
      "You have 41 pages in your data\n",
      "There are 1137 characters in the page\n"
     ]
    }
   ],
   "source": [
    "data = load_document(\"files/us_constitution.pdf\")\n",
    "#print(data[1].page_content)\n",
    "#print(data[10].metadata)\n",
    "print(f\"You have {len(data)} pages in your data\")\n",
    "print(f\"There are {len(data[20].page_content)} characters in the page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab4abd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = load_document(\"files/the_great_gatsby.docx\")\n",
    "#print(data[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a26aa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = load_from_wikipedia(\"GPT-4\", \"de\")\n",
    "#print(data[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c215261",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\n",
      "Representatives\n",
      "shall\n",
      "chuse\n",
      "their\n",
      "Speaker\n",
      "and\n",
      "other\n",
      "Of ficers;and\n",
      "shall\n",
      "have\n",
      "the\n",
      "sole\n",
      "Power\n",
      "of\n",
      "Impeachment.\n",
      "Section\n",
      "3:\n",
      "The\n",
      "Senate\n",
      "The\n",
      "Senate\n",
      "of\n",
      "the\n",
      "United\n",
      "States\n",
      "shall\n",
      "be\n",
      "composed\n",
      "of\n",
      "two\n",
      "Senators\n",
      "from\n",
      "each\n",
      "State,\n",
      "chosen\n",
      "by\n",
      "the\n",
      "Legislature\n",
      "thereof,\n",
      "for\n",
      "six\n"
     ]
    }
   ],
   "source": [
    "chunks = chunk_data(data)\n",
    "print(len(chunks))\n",
    "print(chunks[10].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5dd36832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 16711\n",
      "Embedding Cost in USD: 0.006684\n"
     ]
    }
   ],
   "source": [
    "print_embedding_cost(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2393c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting all indexes ...\n",
      "Ok\n"
     ]
    }
   ],
   "source": [
    "delete_pinecone_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20174236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index askadocument and embeddings ...Ok\n"
     ]
    }
   ],
   "source": [
    "index_name = \"askadocument\"\n",
    "vector_store = insert_or_fetch_embeddings(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8837bf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document being referred to is the United States Constitution. It is a foundational document that outlines the structure and powers of the U.S. government. It establishes the principles of governance and protects the rights and liberties of the people. The Constitution sets out the framework for the federal system, including the separation of powers among the three branches of government and the balance of power between the federal government and the states. It also includes provisions for the amendment process and the supremacy of federal law. Overall, the Constitution aims to create a more perfect union, ensure justice, maintain domestic tranquility, provide for the common defense, promote the general welfare, and secure the blessings of liberty for the people.\n"
     ]
    }
   ],
   "source": [
    "q = \"What is the whole document about?\"\n",
    "answer = ask_and_get_answer(vector_store, q)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98f2d374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write Quit or Exit to quit\n",
      "Question #1; How many amendments are in the US Constitution?\n",
      "\n",
      "Answer: There are currently 27 amendments in the US Constitution.\n",
      "\n",
      " -------------------------------------------------- \n",
      "\n",
      "Question #2; Multiply that number by 2\n",
      "\n",
      "Answer: To multiply the number 1,760 million by 2, the result would be 3,520 million.\n",
      "\n",
      " -------------------------------------------------- \n",
      "\n",
      "Question #3; quit\n",
      "Quitting ... bye bye!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "i = 1\n",
    "print(\"Write Quit or Exit to quit\")\n",
    "while True:\n",
    "    q = input(f\"Question #{i}; \")\n",
    "    i = i+1\n",
    "    if q.lower() in [\"quit\", \"exit\"]:\n",
    "        print(\"Quitting ... bye bye!\")\n",
    "        time.sleep(2)\n",
    "        break\n",
    "    \n",
    "    answer = ask_and_get_answer(vector_store, q)\n",
    "    print(f\"\\nAnswer: {answer}\")\n",
    "    print(f'\\n {\"-\" * 50} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67214c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting all indexes ...\n",
      "Ok\n"
     ]
    }
   ],
   "source": [
    "delete_pinecone_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52ce3650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index chatgpt and embeddings ...Ok\n"
     ]
    }
   ],
   "source": [
    "data = load_from_wikipedia(\"ChatGPT\", \"es\")\n",
    "chunks = chunk_data(data)\n",
    "index_name = \"chatgpt\"\n",
    "vector_store = insert_or_fetch_embeddings(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "519d46a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT es un modelo de lenguaje desarrollado por OpenAI. Es una versión de su modelo GPT (Generative Pre-trained Transformer) específicamente diseñada para generar respuestas en conversaciones de chat. ChatGPT puede entender y responder preguntas y comentarios en lenguaje natural de una manera coherente y contextualmente relevante.\n"
     ]
    }
   ],
   "source": [
    "q = \"Que es ChatGPT\"\n",
    "answer = ask_and_get_answer(vector_store, q)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96b801ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are currently 27 amendments in the U.S. Constitution.\n",
      "[('How many amendments are in the U.S. Constitution?', 'There are currently 27 amendments in the U.S. Constitution.')]\n"
     ]
    }
   ],
   "source": [
    "# Asking with Memory\n",
    "chat_history = []\n",
    "question = \"How many amendments are in the U.S. Constitution?\"\n",
    "result, chat_history = ask_with_memory(vector_store, question, chat_history)\n",
    "print(result['answer'])\n",
    "print(chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29c9df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Multiply that number by 2\"\n",
    "result, chat_history = ask_with_memory(vector_store, question, chat_history)\n",
    "print(result['answer'])\n",
    "print(chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd4f6ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9576f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
