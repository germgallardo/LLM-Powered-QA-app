{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6faa46c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f970fa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pypdf -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f192a9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install docx2txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "454e7bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wikipedia -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7294af2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_document(file):\n",
    "    import os\n",
    "    name, extension = os.path.splitext(file)\n",
    "    \n",
    "    if extension == \".pdf\":\n",
    "        from langchain.document_loaders import PyPDFLoader\n",
    "        print(f\"Loading {file}\")\n",
    "        loader = PyPDFLoader(file)\n",
    "    elif extension == \".docx\":\n",
    "        from langchain.document_loaders import Docx2txtLoader\n",
    "        print(f\"Loading {file}\")\n",
    "        loader = Docx2txtLoader(file)\n",
    "    else:\n",
    "        print(\"Document format is not supported!\")\n",
    "        return None\n",
    "    \n",
    "    data = loader.load()\n",
    "    return data\n",
    "\n",
    "# Wikipedia\n",
    "def load_from_wikipedia(query, lang=\"en\", load_max_docs=2):\n",
    "    from langchain.document_loaders import WikipediaLoader\n",
    "    loader = WikipediaLoader(query=query, lang=lang, load_max_docs=load_max_docs)\n",
    "    data = loader.load()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d951207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_data(data, chunk_size=256):\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=0)\n",
    "    chunks = text_splitter.split_documents(data)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e02bb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_embedding_cost(texts):\n",
    "    import tiktoken\n",
    "    enc = tiktoken.encoding_for_model(\"text-embedding-ada-002\")\n",
    "    total_tokens = sum([len(enc.encode(page.page_content)) for page in texts])\n",
    "    print(f\"Total tokens: {total_tokens}\")\n",
    "    print(f\"Embedding Cost in USD: {total_tokens / 1000 * 0.0004:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17c3d2a",
   "metadata": {},
   "source": [
    "### Embedding and Uploading to a Vector Database (Pinecone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b8af210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_or_fetch_embeddings(index_name):\n",
    "    import pinecone\n",
    "    from langchain.vectorstores import Pinecone\n",
    "    from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "    \n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    \n",
    "    pinecone.init(api_key=os.environ.get(\"PINECONE_API_KEY\"), environment=os.environ.get(\"PINECONE_ENV\"))\n",
    "    \n",
    "    if index_name in pinecone.list_indexes():\n",
    "        print(f\"Index {index_name} already exists. Loading embeddings ...\", end=\"\")\n",
    "        vector_store = Pinecone.from_existing_index(index_name, embeddings)\n",
    "    else:\n",
    "        print(f\"Creating index {index_name} and embeddings ...\", end=\"\")\n",
    "        pinecone.create_index(index_name, dimension=1536, metric=\"cosine\")\n",
    "        vector_store = Pinecone.from_documents(chunks, embeddings, index_name=index_name)\n",
    "        print(\"Ok\")\n",
    "    \n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fab7944a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_pinecone_index(index_name=\"all\"):\n",
    "    import pinecone\n",
    "    pinecone.init(api_key=os.environ.get(\"PINECONE_API_KEY\"), environment=os.environ.get(\"PINECONE_ENV\"))\n",
    "    \n",
    "    if index_name == \"all\":\n",
    "        indexes = pinecone.list_indexes()\n",
    "        print(\"Deleting all indexes ...\")\n",
    "        for index in indexes:\n",
    "            pinecone.delete_index(index)\n",
    "        print(\"Ok\")\n",
    "    else:\n",
    "        print(f\"Deleting index {index_name} ...\", end=\"\")\n",
    "        pinecone.delete_index(index_name)\n",
    "        print(\"Ok\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711f1d0c",
   "metadata": {},
   "source": [
    "### Asking and Getting Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "706deeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_and_get_answer(vector_store, q):\n",
    "    from langchain.chains import RetrievalQA\n",
    "    from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=1)\n",
    "\n",
    "    retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\" : 3})\n",
    "\n",
    "    chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
    "    \n",
    "    answer = chain.run(q)\n",
    "    \n",
    "    return answer\n",
    "\n",
    "def ask_with_memory(vector_store, question, chat_history=[]):\n",
    "    from langchain.chains import ConversationalRetrievalChain\n",
    "    from langchain.chat_models import ChatOpenAI\n",
    "    \n",
    "    llm = ChatOpenAI(temperature=1)\n",
    "    retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k' : 3})\n",
    "    \n",
    "    crc = ConversationalRetrievalChain.from_llm(llm, retriever)\n",
    "    result = crc({'question' : question, 'chat_history' : chat_history})\n",
    "    chat_history.append((question, result['answer']))\n",
    "    \n",
    "    return result, chat_history  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7e3d60",
   "metadata": {},
   "source": [
    "### Running Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81143199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files/us_constitution.pdf\n",
      "You have 41 pages in your data\n",
      "There are 1137 characters in the page\n"
     ]
    }
   ],
   "source": [
    "data = load_document(\"files/us_constitution.pdf\")\n",
    "#print(data[1].page_content)\n",
    "#print(data[10].metadata)\n",
    "print(f\"You have {len(data)} pages in your data\")\n",
    "print(f\"There are {len(data[20].page_content)} characters in the page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a671d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = load_document(\"files/the_great_gatsby.docx\")\n",
    "#print(data[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbfcdeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = load_from_wikipedia(\"GPT-4\", \"de\")\n",
    "#print(data[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7a3dc97",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190\n",
      "Representatives\n",
      "shall\n",
      "chuse\n",
      "their\n",
      "Speaker\n",
      "and\n",
      "other\n",
      "Of ficers;and\n",
      "shall\n",
      "have\n",
      "the\n",
      "sole\n",
      "Power\n",
      "of\n",
      "Impeachment.\n",
      "Section\n",
      "3:\n",
      "The\n",
      "Senate\n",
      "The\n",
      "Senate\n",
      "of\n",
      "the\n",
      "United\n",
      "States\n",
      "shall\n",
      "be\n",
      "composed\n",
      "of\n",
      "two\n",
      "Senators\n",
      "from\n",
      "each\n",
      "State,\n",
      "chosen\n",
      "by\n",
      "the\n",
      "Legislature\n",
      "thereof,\n",
      "for\n",
      "six\n"
     ]
    }
   ],
   "source": [
    "chunks = chunk_data(data)\n",
    "print(len(chunks))\n",
    "print(chunks[10].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8156d215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 16711\n",
      "Embedding Cost in USD: 0.006684\n"
     ]
    }
   ],
   "source": [
    "print_embedding_cost(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e551667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\germa\\anaconda3\\Lib\\site-packages\\pinecone\\index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting all indexes ...\n",
      "Ok\n"
     ]
    }
   ],
   "source": [
    "delete_pinecone_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d9ffea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index askadocument and embeddings ...Ok\n"
     ]
    }
   ],
   "source": [
    "index_name = \"askadocument\"\n",
    "vector_store = insert_or_fetch_embeddings(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d6cde68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document is about the United States Constitution. It outlines the purpose of the Constitution, which is to form a more perfect union, establish justice, ensure domestic tranquility, provide for the common defense, promote the general welfare, and secure the blessings of liberty. It also discusses the authority of the Constitution and the supremacy of treaties made under the authority of the United States. Additionally, it mentions the rights and privileges of citizens in each state.\n"
     ]
    }
   ],
   "source": [
    "q = \"What is the whole document about?\"\n",
    "answer = ask_and_get_answer(vector_store, q)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e8c08c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write Quit or Exit to quit\n",
      "Question #1; How many amendments are in the US Constitution?\n",
      "\n",
      "Answer: There are currently 27 amendments in the US Constitution.\n",
      "\n",
      " -------------------------------------------------- \n",
      "\n",
      "Question #2; Multiply that number by 2\n",
      "\n",
      "Answer: To multiply the number 1,760 million by 2, the result would be 3,520 million.\n",
      "\n",
      " -------------------------------------------------- \n",
      "\n",
      "Question #3; quit\n",
      "Quitting ... bye bye!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "i = 1\n",
    "print(\"Write Quit or Exit to quit\")\n",
    "while True:\n",
    "    q = input(f\"Question #{i}; \")\n",
    "    i = i+1\n",
    "    if q.lower() in [\"quit\", \"exit\"]:\n",
    "        print(\"Quitting ... bye bye!\")\n",
    "        time.sleep(2)\n",
    "        break\n",
    "    \n",
    "    answer = ask_and_get_answer(vector_store, q)\n",
    "    print(f\"\\nAnswer: {answer}\")\n",
    "    print(f'\\n {\"-\" * 50} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2d08a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting all indexes ...\n",
      "Ok\n"
     ]
    }
   ],
   "source": [
    "delete_pinecone_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0bef94e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index chatgpt and embeddings ...Ok\n"
     ]
    }
   ],
   "source": [
    "data = load_from_wikipedia(\"ChatGPT\", \"es\")\n",
    "chunks = chunk_data(data)\n",
    "index_name = \"chatgpt\"\n",
    "vector_store = insert_or_fetch_embeddings(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22190b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT es una aplicación de chatbot de inteligencia artificial desarrollada por OpenAI en 2022. Es un modelo de lenguaje pre-entrenado que se especializa en el diálogo. Puede interactuar con los usuarios y responder preguntas sobre diversos temas, incluyendo fenómenos de Internet y lenguajes de programación como Python. A diferencia de su predecesor, ChatGPT se ha diseñado para reducir respuestas dañinas y engañosas, proporcionando información más precisa y confiable.\n"
     ]
    }
   ],
   "source": [
    "q = \"Que es ChatGPT\"\n",
    "answer = ask_and_get_answer(vector_store, q)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27965423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are currently 27 amendments in the U.S. Constitution.\n",
      "[('How many amendments are in the U.S. Constitution?', 'There are currently 27 amendments in the U.S. Constitution.')]\n"
     ]
    }
   ],
   "source": [
    "# Asking with Memory\n",
    "chat_history = []\n",
    "question = \"How many amendments are in the U.S. Constitution?\"\n",
    "result, chat_history = ask_with_memory(vector_store, question, chat_history)\n",
    "print(result['answer'])\n",
    "print(chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a44765e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given information does not provide a specific number to multiply by 2. Therefore, I cannot provide the result of multiplying that number by 2.\n",
      "[('How many amendments are in the U.S. Constitution?', 'There are currently 27 amendments in the U.S. Constitution.'), ('Multiply that number by 2', 'The given information does not provide a specific number to multiply by 2. Therefore, I cannot provide the result of multiplying that number by 2.')]\n"
     ]
    }
   ],
   "source": [
    "question = \"Multiply that number by 2\"\n",
    "result, chat_history = ask_with_memory(vector_store, question, chat_history)\n",
    "print(result['answer'])\n",
    "print(chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06dc46d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea78ae02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
